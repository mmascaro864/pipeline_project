{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(database_filepath):\n",
    "    sql_url = 'sqlite:///'+ database_filepath\n",
    "    table = os.path.basename(database_filepath)\n",
    "    engine = create_engine(sql_url)\n",
    "    df = pd.read_sql_table(table, engine)\n",
    "    \n",
    "    X = df['message'].values\n",
    "    y = df[df.columns[4:]].values\n",
    "    \n",
    "    #category_names = y.columns\n",
    "    category_names = list(df.columns)[4:]\n",
    "    \n",
    "    return X, y, category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_filepath = 'data/DisasterResponse.db'\n",
    "\n",
    "X, y, category_names = load_data(database_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26216,), (26216, 35))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_vect = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<26216x35121 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 535982 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Debug(BaseEstimator, TransformerMixin):\n",
    "    def transform(self, X):\n",
    "        print(X.shape)\n",
    "        return X\n",
    "    \n",
    "    def fit(self, X, y = None, **fit_params):\n",
    "        return self "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaseNormalizer(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    CaseNormalizer class: \n",
    "        - Feature of machine learning pipeline model\n",
    "        - custom transformer that transforms a text array to lower case\n",
    "        and removes white space.\n",
    "\n",
    "        In: \n",
    "            text array\n",
    "        Out: \n",
    "            Pandas Series of transformed text\n",
    "    '''\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        X_vect = vectorizer.fit_transform(X)\n",
    "        print(X_vect)\n",
    "        return X_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StartingVerbExtractor(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    StartingVerbExtractor class:\n",
    "        - Feature of machine learning model pipeline\n",
    "        - Checks whether first word in sentence is a verb\n",
    "\n",
    "        In: \n",
    "            text array\n",
    "        Out: \n",
    "            Pandas DataFrame of tagged text\n",
    "    '''\n",
    "\n",
    "    def starting_verb(self, text):\n",
    "        sentence_list = sent_tokenize(text)\n",
    "        for sentence in sentence_list:\n",
    "            pos_tags = pos_tag(tokenize(sentence))\n",
    "            first_word, first_tag = pos_tags[0]\n",
    "            if first_tag in ['VB', 'VBP'] or first_word == 'RT':\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_tagged = pd.Series(X).apply(self.starting_verb)\n",
    "        X_tagged = pd.DataFrame(X_tagged)\n",
    "        X_tagged[0] = X_tagged[0].astype(int)\n",
    "        return X_tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    '''\n",
    "    tokenize:\n",
    "        Split text into words, normalize case, reduce words to their root\n",
    "        In:\n",
    "            text - message text from disaster dataset\n",
    "        \n",
    "        Out:\n",
    "            clean_tokens - tokenized and lemmatized text\n",
    "    '''\n",
    "    url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    \n",
    "    # get list of all urls using regex\n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    \n",
    "    # replace each url in text string with placeholder\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, 'urlplaceholder')\n",
    "\n",
    "    # tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # initate case_normalizer and normalize text\n",
    "    case_normalizer = CaseNormalizer()\n",
    "    normalized_tokens = case_normalizer.transform(tokens)\n",
    "    \n",
    "    # initiate lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # iterate through each token and lemmatize text\n",
    "    clean_tokens = []\n",
    "    for token in normalized_tokens:\n",
    "        \n",
    "        clean_token = lemmatizer.lemmatize(token)\n",
    "        clean_tokens.append(clean_token)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/9k/mzsl98qj485cy49cyb6gm8c40000gn/T/ipykernel_58836/3209499250.py\u001b[0m(19)\u001b[0;36mtransform\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     17 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     18 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 19 \u001b[0;31m        \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     20 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     21 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> continue\n",
      "['the' 'training' 'demonstrated' 'how' 'to' 'enhance' 'micro']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the', 'training', 'demonstrated', 'how', 'to', 'enhance', 'micro']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'The training demonstrated how to   enhance Micro'\n",
    "tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    '''\n",
    "        build_model:\n",
    "            - Build Natural Language Processing ML pipeline model\n",
    "            - Processes and transforms text messages and applies a classifier\n",
    "\n",
    "            In:\n",
    "                - None\n",
    "\n",
    "            Out: pipeline model\n",
    "    '''\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            \n",
    "            ('nlp_pipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('debug', Debug()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('debug1', Debug())\n",
    "            ])),\n",
    "\n",
    "            ('starting_verb', StartingVerbExtractor()),\n",
    "            ('debug2', Debug()),\n",
    "            ('case_normalizer', CaseNormalizer()),\n",
    "            ('debug3', Debug())\n",
    "        ])),\n",
    "    \n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "    ])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('features',\n",
       "   FeatureUnion(transformer_list=[('nlp_pipeline',\n",
       "                                   Pipeline(steps=[('vect',\n",
       "                                                    CountVectorizer(tokenizer=<function tokenize at 0x7fe0d9c53b80>)),\n",
       "                                                   ('debug', Debug()),\n",
       "                                                   ('tfidf', TfidfTransformer()),\n",
       "                                                   ('toarray',\n",
       "                                                    FunctionTransformer(func=<function <lambda> at 0x7fe0d9c530d0>)),\n",
       "                                                   ('debug1', Debug())])),\n",
       "                                  ('starting_verb', StartingVerbExtractor()),\n",
       "                                  ('debug2', Debug()),\n",
       "                                  ('case_normalizer', CaseNormalizer()),\n",
       "                                  ('debug3', Debug())])),\n",
       "  ('clf', MultiOutputClassifier(estimator=RandomForestClassifier()))],\n",
       " 'verbose': False,\n",
       " 'features': FeatureUnion(transformer_list=[('nlp_pipeline',\n",
       "                                 Pipeline(steps=[('vect',\n",
       "                                                  CountVectorizer(tokenizer=<function tokenize at 0x7fe0d9c53b80>)),\n",
       "                                                 ('debug', Debug()),\n",
       "                                                 ('tfidf', TfidfTransformer()),\n",
       "                                                 ('toarray',\n",
       "                                                  FunctionTransformer(func=<function <lambda> at 0x7fe0d9c530d0>)),\n",
       "                                                 ('debug1', Debug())])),\n",
       "                                ('starting_verb', StartingVerbExtractor()),\n",
       "                                ('debug2', Debug()),\n",
       "                                ('case_normalizer', CaseNormalizer()),\n",
       "                                ('debug3', Debug())]),\n",
       " 'clf': MultiOutputClassifier(estimator=RandomForestClassifier()),\n",
       " 'features__n_jobs': None,\n",
       " 'features__transformer_list': [('nlp_pipeline',\n",
       "   Pipeline(steps=[('vect',\n",
       "                    CountVectorizer(tokenizer=<function tokenize at 0x7fe0d9c53b80>)),\n",
       "                   ('debug', Debug()), ('tfidf', TfidfTransformer()),\n",
       "                   ('toarray',\n",
       "                    FunctionTransformer(func=<function <lambda> at 0x7fe0d9c530d0>)),\n",
       "                   ('debug1', Debug())])),\n",
       "  ('starting_verb', StartingVerbExtractor()),\n",
       "  ('debug2', Debug()),\n",
       "  ('case_normalizer', CaseNormalizer()),\n",
       "  ('debug3', Debug())],\n",
       " 'features__transformer_weights': None,\n",
       " 'features__verbose': False,\n",
       " 'features__nlp_pipeline': Pipeline(steps=[('vect',\n",
       "                  CountVectorizer(tokenizer=<function tokenize at 0x7fe0d9c53b80>)),\n",
       "                 ('debug', Debug()), ('tfidf', TfidfTransformer()),\n",
       "                 ('toarray',\n",
       "                  FunctionTransformer(func=<function <lambda> at 0x7fe0d9c530d0>)),\n",
       "                 ('debug1', Debug())]),\n",
       " 'features__starting_verb': StartingVerbExtractor(),\n",
       " 'features__debug2': Debug(),\n",
       " 'features__case_normalizer': CaseNormalizer(),\n",
       " 'features__debug3': Debug(),\n",
       " 'features__nlp_pipeline__memory': None,\n",
       " 'features__nlp_pipeline__steps': [('vect',\n",
       "   CountVectorizer(tokenizer=<function tokenize at 0x7fe0d9c53b80>)),\n",
       "  ('debug', Debug()),\n",
       "  ('tfidf', TfidfTransformer()),\n",
       "  ('toarray', FunctionTransformer(func=<function <lambda> at 0x7fe0d9c530d0>)),\n",
       "  ('debug1', Debug())],\n",
       " 'features__nlp_pipeline__verbose': False,\n",
       " 'features__nlp_pipeline__vect': CountVectorizer(tokenizer=<function tokenize at 0x7fe0d9c53b80>),\n",
       " 'features__nlp_pipeline__debug': Debug(),\n",
       " 'features__nlp_pipeline__tfidf': TfidfTransformer(),\n",
       " 'features__nlp_pipeline__toarray': FunctionTransformer(func=<function <lambda> at 0x7fe0d9c530d0>),\n",
       " 'features__nlp_pipeline__debug1': Debug(),\n",
       " 'features__nlp_pipeline__vect__analyzer': 'word',\n",
       " 'features__nlp_pipeline__vect__binary': False,\n",
       " 'features__nlp_pipeline__vect__decode_error': 'strict',\n",
       " 'features__nlp_pipeline__vect__dtype': numpy.int64,\n",
       " 'features__nlp_pipeline__vect__encoding': 'utf-8',\n",
       " 'features__nlp_pipeline__vect__input': 'content',\n",
       " 'features__nlp_pipeline__vect__lowercase': True,\n",
       " 'features__nlp_pipeline__vect__max_df': 1.0,\n",
       " 'features__nlp_pipeline__vect__max_features': None,\n",
       " 'features__nlp_pipeline__vect__min_df': 1,\n",
       " 'features__nlp_pipeline__vect__ngram_range': (1, 1),\n",
       " 'features__nlp_pipeline__vect__preprocessor': None,\n",
       " 'features__nlp_pipeline__vect__stop_words': None,\n",
       " 'features__nlp_pipeline__vect__strip_accents': None,\n",
       " 'features__nlp_pipeline__vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'features__nlp_pipeline__vect__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'features__nlp_pipeline__vect__vocabulary': None,\n",
       " 'features__nlp_pipeline__tfidf__norm': 'l2',\n",
       " 'features__nlp_pipeline__tfidf__smooth_idf': True,\n",
       " 'features__nlp_pipeline__tfidf__sublinear_tf': False,\n",
       " 'features__nlp_pipeline__tfidf__use_idf': True,\n",
       " 'features__nlp_pipeline__toarray__accept_sparse': False,\n",
       " 'features__nlp_pipeline__toarray__check_inverse': True,\n",
       " 'features__nlp_pipeline__toarray__func': <function __main__.<lambda>(x)>,\n",
       " 'features__nlp_pipeline__toarray__inv_kw_args': None,\n",
       " 'features__nlp_pipeline__toarray__inverse_func': None,\n",
       " 'features__nlp_pipeline__toarray__kw_args': None,\n",
       " 'features__nlp_pipeline__toarray__validate': False,\n",
       " 'clf__estimator__bootstrap': True,\n",
       " 'clf__estimator__ccp_alpha': 0.0,\n",
       " 'clf__estimator__class_weight': None,\n",
       " 'clf__estimator__criterion': 'gini',\n",
       " 'clf__estimator__max_depth': None,\n",
       " 'clf__estimator__max_features': 'auto',\n",
       " 'clf__estimator__max_leaf_nodes': None,\n",
       " 'clf__estimator__max_samples': None,\n",
       " 'clf__estimator__min_impurity_decrease': 0.0,\n",
       " 'clf__estimator__min_samples_leaf': 1,\n",
       " 'clf__estimator__min_samples_split': 2,\n",
       " 'clf__estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'clf__estimator__n_estimators': 100,\n",
       " 'clf__estimator__n_jobs': None,\n",
       " 'clf__estimator__oob_score': False,\n",
       " 'clf__estimator__random_state': None,\n",
       " 'clf__estimator__verbose': 0,\n",
       " 'clf__estimator__warm_start': False,\n",
       " 'clf__estimator': RandomForestClassifier(),\n",
       " 'clf__n_jobs': None}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/9k/mzsl98qj485cy49cyb6gm8c40000gn/T/ipykernel_58836/2999287524.py\u001b[0m(19)\u001b[0;36mtransform\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     17 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     18 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 19 \u001b[0;31m        \u001b[0mX_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     20 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_vect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     21 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mX_vect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> continue\n",
      "  (0, 7)\t1\n",
      "  (2, 17)\t1\n",
      "  (3, 8)\t1\n",
      "  (4, 22)\t1\n",
      "  (5, 1)\t1\n",
      "  (6, 4)\t1\n",
      "  (7, 18)\t1\n",
      "  (8, 17)\t1\n",
      "  (9, 14)\t1\n",
      "  (10, 10)\t1\n",
      "  (11, 0)\t1\n",
      "  (12, 19)\t1\n",
      "  (13, 10)\t1\n",
      "  (14, 13)\t1\n",
      "  (15, 20)\t1\n",
      "  (16, 15)\t1\n",
      "  (17, 5)\t1\n",
      "  (18, 6)\t1\n",
      "  (19, 17)\t1\n",
      "  (20, 11)\t1\n",
      "  (21, 12)\t1\n",
      "  (22, 9)\t1\n",
      "  (24, 2)\t1\n",
      "  (25, 21)\t1\n",
      "  (26, 2)\t1\n",
      "  (27, 17)\t1\n",
      "  (28, 3)\t1\n",
      "  (29, 14)\t1\n",
      "  (30, 10)\t1\n",
      "  (31, 13)\t1\n",
      "  (32, 16)\t1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'csr_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# train classifier\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model()\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py:390\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    389\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m--> 390\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py:348\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    346\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py:1172\u001b[0m, in \u001b[0;36mFeatureUnion.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;124;03m\"\"\"Fit all transformers, transform the data and concatenate results.\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \n\u001b[1;32m   1154\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;124;03m        sum of `n_components` (output dimension) over transformers.\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1172\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parallel_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_fit_transform_one\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m results:\n\u001b[1;32m   1174\u001b[0m         \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py:1194\u001b[0m, in \u001b[0;36mFeatureUnion._parallel_func\u001b[0;34m(self, X, y, fit_params, func)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformer_weights()\n\u001b[1;32m   1192\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter())\n\u001b[0;32m-> 1194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFeatureUnion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1048\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1048\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1049\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 864\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    781\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 782\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py:426\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03mFits all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03m    Transformed samples.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    425\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m--> 426\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m last_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py:348\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    346\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1330\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1322\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1323\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1324\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1325\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1326\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1327\u001b[0m             )\n\u001b[1;32m   1328\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1330\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1333\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1201\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1200\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1201\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1202\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1203\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:115\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    113\u001b[0m     doc \u001b[38;5;241m=\u001b[39m preprocessor(doc)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ngrams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_words \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[35], line 34\u001b[0m, in \u001b[0;36mtokenize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     31\u001b[0m clean_tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m normalized_tokens:\n\u001b[0;32m---> 34\u001b[0m     clean_token \u001b[38;5;241m=\u001b[39m \u001b[43mlemmatizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     clean_tokens\u001b[38;5;241m.\u001b[39mappend(clean_token)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clean_tokens\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/nltk/stem/wordnet.py:45\u001b[0m, in \u001b[0;36mWordNetLemmatizer.lemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatize\u001b[39m(\u001b[38;5;28mself\u001b[39m, word: \u001b[38;5;28mstr\u001b[39m, pos: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124;03m\"\"\"Lemmatize `word` using WordNet's built-in morphy function.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    Returns the input word unchanged if it cannot be found in WordNet.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m    :return: The lemma of `word`, for the given `pos`.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     lemmas \u001b[38;5;241m=\u001b[39m \u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_morphy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(lemmas, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m lemmas \u001b[38;5;28;01melse\u001b[39;00m word\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/nltk/corpus/reader/wordnet.py:2032\u001b[0m, in \u001b[0;36mWordNetCorpusReader._morphy\u001b[0;34m(self, form, pos, check_exceptions)\u001b[0m\n\u001b[1;32m   2030\u001b[0m \u001b[38;5;66;03m# 0. Check the exception lists\u001b[39;00m\n\u001b[1;32m   2031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_exceptions:\n\u001b[0;32m-> 2032\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mform\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexceptions\u001b[49m:\n\u001b[1;32m   2033\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m filter_forms([form] \u001b[38;5;241m+\u001b[39m exceptions[form])\n\u001b[1;32m   2035\u001b[0m \u001b[38;5;66;03m# 1. Apply rules once to the input to get y1, y2, y3, etc.\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'csr_matrix'"
     ]
    }
   ],
   "source": [
    "# split data into test and train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# train classifier\n",
    "model = build_model()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.81      0.97      0.88      4998\n",
      "               request       0.89      0.44      0.59      1079\n",
      "                 offer       0.00      0.00      0.00        27\n",
      "           aid_related       0.78      0.61      0.69      2712\n",
      "          medical_help       0.71      0.05      0.09       508\n",
      "      medical_products       0.79      0.07      0.12       341\n",
      "     search_and_rescue       0.50      0.02      0.04       185\n",
      "              security       0.00      0.00      0.00       128\n",
      "              military       0.80      0.06      0.11       208\n",
      "                 water       0.95      0.21      0.34       413\n",
      "                  food       0.88      0.38      0.53       715\n",
      "               shelter       0.84      0.25      0.39       553\n",
      "              clothing       0.88      0.08      0.15        83\n",
      "                 money       0.67      0.01      0.03       153\n",
      "        missing_people       0.00      0.00      0.00        78\n",
      "              refugees       0.80      0.02      0.03       225\n",
      "                 death       0.79      0.10      0.18       300\n",
      "             other_aid       0.56      0.01      0.02       866\n",
      "infrastructure_related       0.00      0.00      0.00       409\n",
      "             transport       0.89      0.05      0.10       299\n",
      "             buildings       0.84      0.06      0.12       335\n",
      "           electricity       0.57      0.03      0.06       136\n",
      "                 tools       0.00      0.00      0.00        35\n",
      "             hospitals       0.00      0.00      0.00        61\n",
      "                 shops       0.00      0.00      0.00        26\n",
      "           aid_centers       0.00      0.00      0.00        73\n",
      "  other_infrastructure       0.00      0.00      0.00       285\n",
      "       weather_related       0.87      0.62      0.72      1816\n",
      "                floods       0.90      0.39      0.55       561\n",
      "                 storm       0.81      0.42      0.55       640\n",
      "                  fire       0.00      0.00      0.00        72\n",
      "            earthquake       0.89      0.72      0.80       600\n",
      "                  cold       0.67      0.07      0.13       107\n",
      "         other_weather       0.80      0.02      0.05       334\n",
      "         direct_report       0.85      0.33      0.48      1245\n",
      "\n",
      "             micro avg       0.82      0.49      0.61     20606\n",
      "             macro avg       0.56      0.17      0.22     20606\n",
      "          weighted avg       0.76      0.49      0.53     20606\n",
      "           samples avg       0.69      0.46      0.51     20606\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=category_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9447273202842319"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (y_pred == y_test).mean().mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.unique(y_pred)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(tokenizer=<function tokenize at 0x7f844b4254c0>)),\n",
       "  ('tfidf', TfidfTransformer()),\n",
       "  ('clf', MultiOutputClassifier(estimator=RandomForestClassifier()))],\n",
       " 'verbose': False,\n",
       " 'vect': CountVectorizer(tokenizer=<function tokenize at 0x7f844b4254c0>),\n",
       " 'tfidf': TfidfTransformer(),\n",
       " 'clf': MultiOutputClassifier(estimator=RandomForestClassifier()),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'clf__estimator__bootstrap': True,\n",
       " 'clf__estimator__ccp_alpha': 0.0,\n",
       " 'clf__estimator__class_weight': None,\n",
       " 'clf__estimator__criterion': 'gini',\n",
       " 'clf__estimator__max_depth': None,\n",
       " 'clf__estimator__max_features': 'auto',\n",
       " 'clf__estimator__max_leaf_nodes': None,\n",
       " 'clf__estimator__max_samples': None,\n",
       " 'clf__estimator__min_impurity_decrease': 0.0,\n",
       " 'clf__estimator__min_samples_leaf': 1,\n",
       " 'clf__estimator__min_samples_split': 2,\n",
       " 'clf__estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'clf__estimator__n_estimators': 100,\n",
       " 'clf__estimator__n_jobs': None,\n",
       " 'clf__estimator__oob_score': False,\n",
       " 'clf__estimator__random_state': None,\n",
       " 'clf__estimator__verbose': 0,\n",
       " 'clf__estimator__warm_start': False,\n",
       " 'clf__estimator': RandomForestClassifier(),\n",
       " 'clf__n_jobs': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('vect',\n",
       "                                        CountVectorizer(tokenizer=<function tokenize at 0x7f844b4254c0>)),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf',\n",
       "                                        MultiOutputClassifier(estimator=RandomForestClassifier()))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'clf__estimator__min_samples_split': [2, 4],\n",
       "                         'clf__estimator__n_estimators': [10]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'clf__estimator__n_estimators': [10],\n",
    "    'clf__estimator__min_samples_split': [2, 4]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(model, param_grid=parameters, verbose = 1, n_jobs = -1)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.82      0.93      0.87      5013\n",
      "               request       0.82      0.37      0.51      1107\n",
      "                 offer       0.00      0.00      0.00        27\n",
      "           aid_related       0.75      0.50      0.60      2705\n",
      "          medical_help       0.71      0.12      0.20       503\n",
      "      medical_products       0.70      0.05      0.09       333\n",
      "     search_and_rescue       0.61      0.06      0.11       184\n",
      "              security       0.25      0.01      0.02       123\n",
      "              military       0.71      0.12      0.21       225\n",
      "                 water       0.87      0.21      0.34       408\n",
      "                  food       0.84      0.34      0.48       724\n",
      "               shelter       0.88      0.23      0.36       559\n",
      "              clothing       0.59      0.13      0.22        98\n",
      "                 money       0.50      0.02      0.03       170\n",
      "        missing_people       1.00      0.01      0.02        86\n",
      "              refugees       0.78      0.03      0.06       220\n",
      "                 death       0.87      0.11      0.19       312\n",
      "             other_aid       0.45      0.03      0.05       837\n",
      "infrastructure_related       0.20      0.00      0.01       443\n",
      "             transport       0.71      0.05      0.09       331\n",
      "             buildings       0.59      0.08      0.14       335\n",
      "           electricity       0.74      0.11      0.19       131\n",
      "                 tools       0.00      0.00      0.00        35\n",
      "             hospitals       0.00      0.00      0.00        67\n",
      "                 shops       0.00      0.00      0.00        34\n",
      "           aid_centers       0.00      0.00      0.00        77\n",
      "  other_infrastructure       0.00      0.00      0.00       299\n",
      "       weather_related       0.86      0.49      0.62      1849\n",
      "                floods       0.91      0.23      0.37       562\n",
      "                 storm       0.79      0.42      0.55       630\n",
      "                  fire       0.50      0.02      0.03        66\n",
      "            earthquake       0.91      0.59      0.71       601\n",
      "                  cold       0.77      0.08      0.14       132\n",
      "         other_weather       0.64      0.03      0.05       356\n",
      "         direct_report       0.79      0.30      0.44      1265\n",
      "\n",
      "             micro avg       0.81      0.44      0.57     20847\n",
      "             macro avg       0.59      0.16      0.22     20847\n",
      "          weighted avg       0.75      0.44      0.50     20847\n",
      "           samples avg       0.67      0.42      0.47     20847\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=category_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "related                   0.801648\n",
       "request                   0.898383\n",
       "offer                     0.995880\n",
       "aid_related               0.768843\n",
       "medical_help              0.924626\n",
       "medical_products          0.950565\n",
       "search_and_rescue         0.971773\n",
       "security                  0.980470\n",
       "military                  0.969637\n",
       "water                     0.949496\n",
       "food                      0.926457\n",
       "shelter                   0.932865\n",
       "clothing                  0.988251\n",
       "money                     0.976808\n",
       "missing_people            0.988099\n",
       "refugees                  0.966128\n",
       "death                     0.957736\n",
       "other_aid                 0.868172\n",
       "infrastructure_related    0.937443\n",
       "transport                 0.956515\n",
       "buildings                 0.951480\n",
       "electricity               0.979402\n",
       "tools                     0.994660\n",
       "hospitals                 0.990693\n",
       "shops                     0.996033\n",
       "aid_centers               0.988862\n",
       "other_infrastructure      0.956210\n",
       "weather_related           0.868935\n",
       "floods                    0.944156\n",
       "storm                     0.933628\n",
       "fire                      0.989014\n",
       "earthquake                0.966738\n",
       "cold                      0.984284\n",
       "other_weather             0.949954\n",
       "direct_report             0.861611\n",
       "dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (y_pred == y_test).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9k/mzsl98qj485cy49cyb6gm8c40000gn/T/ipykernel_11989/343124394.py:8: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  return pd.Series(X).apply(lambda x: x.lower().strip()).values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "labels = np.unique(y_pred)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [0 1]\n",
      "Confusion Matrix:\n",
      " [[6550    3    1]\n",
      " [   0    0    0]\n",
      " [   0    0    0]]\n",
      "Accuracy: 0.9447273202842319\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "labels = np.unique(y_pred)\n",
    "#confusion_mat = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "confusion_mat = confusion_matrix(y_test.values.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "accuracy = (y_pred == y_test).mean().mean()\n",
    "\n",
    "print(\"Labels:\", labels)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(confusion_matrix(y_test.values.argmax(axis=1), y_pred.argmax(axis=1)), annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred, target_names=category_names, output_dict = True)\n",
    "df_classification_report = pd.DataFrame(report).transpose()\n",
    "#df_classification_report = df_classification_report.sort_values(by=['f1-score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score  support\n",
      "related                  0.807859  0.970788  0.881861   4998.0\n",
      "request                  0.887430  0.438369  0.586849   1079.0\n",
      "offer                    0.000000  0.000000  0.000000     27.0\n",
      "aid_related              0.780066  0.614676  0.687564   2712.0\n",
      "medical_help             0.705882  0.047244  0.088561    508.0\n",
      "medical_products         0.793103  0.067449  0.124324    341.0\n",
      "search_and_rescue        0.500000  0.021622  0.041451    185.0\n",
      "security                 0.000000  0.000000  0.000000    128.0\n",
      "military                 0.800000  0.057692  0.107623    208.0\n",
      "water                    0.945652  0.210654  0.344554    413.0\n",
      "food                     0.881967  0.376224  0.527451    715.0\n",
      "shelter                  0.842424  0.251356  0.387187    553.0\n",
      "clothing                 0.875000  0.084337  0.153846     83.0\n",
      "money                    0.666667  0.013072  0.025641    153.0\n",
      "missing_people           0.000000  0.000000  0.000000     78.0\n",
      "refugees                 0.800000  0.017778  0.034783    225.0\n",
      "death                    0.794872  0.103333  0.182891    300.0\n",
      "other_aid                0.555556  0.011547  0.022624    866.0\n",
      "infrastructure_related   0.000000  0.000000  0.000000    409.0\n",
      "transport                0.888889  0.053512  0.100946    299.0\n",
      "buildings                0.840000  0.062687  0.116667    335.0\n",
      "electricity              0.571429  0.029412  0.055944    136.0\n",
      "tools                    0.000000  0.000000  0.000000     35.0\n",
      "hospitals                0.000000  0.000000  0.000000     61.0\n",
      "shops                    0.000000  0.000000  0.000000     26.0\n",
      "aid_centers              0.000000  0.000000  0.000000     73.0\n",
      "other_infrastructure     0.000000  0.000000  0.000000    285.0\n",
      "weather_related          0.867229  0.622247  0.724591   1816.0\n",
      "floods                   0.897959  0.392157  0.545906    561.0\n",
      "storm                    0.813456  0.415625  0.550155    640.0\n",
      "fire                     0.000000  0.000000  0.000000     72.0\n",
      "earthquake               0.893004  0.723333  0.799263    600.0\n",
      "cold                     0.666667  0.074766  0.134454    107.0\n",
      "other_weather            0.800000  0.023952  0.046512    334.0\n",
      "direct_report            0.847737  0.330924  0.476025   1245.0\n",
      "micro avg                0.821739  0.491265  0.614913  20606.0\n",
      "macro avg                0.563510  0.171850  0.221362  20606.0\n",
      "weighted avg             0.762585  0.491265  0.534242  20606.0\n",
      "samples avg              0.693878  0.464465  0.508497  20606.0\n"
     ]
    }
   ],
   "source": [
    "print(df_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9k/mzsl98qj485cy49cyb6gm8c40000gn/T/ipykernel_11989/343124394.py:8: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  return pd.Series(X).apply(lambda x: x.lower().strip()).values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy by category:\n",
      " related                   0.801648\n",
      "request                   0.898383\n",
      "offer                     0.995880\n",
      "aid_related               0.768843\n",
      "medical_help              0.924626\n",
      "medical_products          0.950565\n",
      "search_and_rescue         0.971773\n",
      "security                  0.980470\n",
      "military                  0.969637\n",
      "water                     0.949496\n",
      "food                      0.926457\n",
      "shelter                   0.932865\n",
      "clothing                  0.988251\n",
      "money                     0.976808\n",
      "missing_people            0.988099\n",
      "refugees                  0.966128\n",
      "death                     0.957736\n",
      "other_aid                 0.868172\n",
      "infrastructure_related    0.937443\n",
      "transport                 0.956515\n",
      "buildings                 0.951480\n",
      "electricity               0.979402\n",
      "tools                     0.994660\n",
      "hospitals                 0.990693\n",
      "shops                     0.996033\n",
      "aid_centers               0.988862\n",
      "other_infrastructure      0.956210\n",
      "weather_related           0.868935\n",
      "floods                    0.944156\n",
      "storm                     0.933628\n",
      "fire                      0.989014\n",
      "earthquake                0.966738\n",
      "cold                      0.984284\n",
      "other_weather             0.949954\n",
      "direct_report             0.861611\n",
      "dtype: float64\n",
      "Overall model accuracy: 0.9447273202842319\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "overall_accuracy = (y_pred == y_test).mean().mean()\n",
    "print('Model accuracy by category:\\n {}'.format(accuracy))\n",
    "print('Overall model accuracy: {}'.format(overall_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StartingVerbExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def starting_verb(self, text):\n",
    "        sentence_list = sent_tokenize(text)\n",
    "        for sentence in sentence_list:\n",
    "            pos_tags = pos_tag(tokenize(sentence))\n",
    "            first_word, first_tag = pos_tags[0]\n",
    "            if first_tag in ['VB', 'VBP'] or first_word == 'RT':\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_tagged = pd.Series(X).apply(self.starting_verb)\n",
    "        return pd.DataFrame(X_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            \n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('tfidf', TfidfTransformer())\n",
    "            ])),\n",
    "\n",
    "            ('starting_verb', StartingVerbExtractor())\n",
    "        ])),\n",
    "    \n",
    "        ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "    \n",
    "    parameters = {\n",
    "    'clf__estimator__n_estimators': [10],\n",
    "    'clf__estimator__min_samples_split': [2, 4]\n",
    "    }\n",
    "\n",
    "    cv = GridSearchCV(model, param_grid=parameters, verbose = 1, n_jobs = -1)\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "source": [
    "cv.fit(X_train, y_train)\n",
    "y_pred = cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23298748855660664\n"
     ]
    }
   ],
   "source": [
    "print(cv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "related                   0.793409\n",
       "request                   0.878242\n",
       "offer                     0.995880\n",
       "aid_related               0.728563\n",
       "medical_help              0.924931\n",
       "medical_products          0.951785\n",
       "search_and_rescue         0.972536\n",
       "security                  0.980928\n",
       "military                  0.967501\n",
       "water                     0.949954\n",
       "food                      0.918523\n",
       "shelter                   0.935002\n",
       "clothing                  0.985810\n",
       "money                     0.974519\n",
       "missing_people            0.987183\n",
       "refugees                  0.966280\n",
       "death                     0.955142\n",
       "other_aid                 0.872597\n",
       "infrastructure_related    0.932103\n",
       "transport                 0.952090\n",
       "buildings                 0.951633\n",
       "electricity               0.981233\n",
       "tools                     0.994660\n",
       "hospitals                 0.989777\n",
       "shops                     0.994812\n",
       "aid_centers               0.988251\n",
       "other_infrastructure      0.954226\n",
       "weather_related           0.832621\n",
       "floods                    0.941257\n",
       "storm                     0.925084\n",
       "fire                      0.989930\n",
       "earthquake                0.951785\n",
       "cold                      0.981080\n",
       "other_weather             0.947055\n",
       "direct_report             0.848337\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (y_pred == y_test).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['implementing', 'a', 'custom', 'transformer', 'from',\n",
       "       'scikit-learn'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CaseNormalizer (BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = pd.Series(X).apply (lambda x: x. lower ()).values\n",
    "        return np.array(X)\n",
    "\n",
    "case_normalizer = CaseNormalizer ()\n",
    "\n",
    "X = ['Implementing', 'a', 'Custom', 'Transformer', 'from', 'SCIKIT-LEARN']\n",
    "case_normalizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = word_tokenize('Are we there yet?')\n",
    "tags = pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "first_word, first_tag = tags[0]\n",
    "if first_tag in ['VB', 'VBP'] or first_word == 'RT':\n",
    "    print('True')\n",
    "else:\n",
    "    print('False')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "def save_model(model, model_filepath):\n",
    "    '''\n",
    "    '''\n",
    "    pk.dump(model, open(model_filepath, \"wb\"))\n",
    "\n",
    "    return\n",
    "model_filepath = 'ml_model.pkl'\n",
    "save_model(model, model_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
